{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7d2897",
   "metadata": {},
   "source": [
    "# Transformer Text Generation\n",
    "\n",
    "In this notebook, we will explore how transformer models (like GPT-2) can generate text based on a given prompt. We will experiment with generating text by adjusting parameters like temperature and sequence length.\n",
    "\n",
    "## Instructions\n",
    "1. Change the prompt below to experiment with different types of text generation.\n",
    "2. Adjust the `max_length` and `temperature` parameters to see how they affect the output.\n",
    "3. Generate at least 3 samples with different prompts and compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbce095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge temporarily blocks effort to ban Harvard from enrolling foreign students.\n",
      "\n",
      "The move comes after the U.S. Department of Education announced it would not allow Harvard to enroll foreign students.\n",
      "\n",
      "The move comes after the U.S. Department\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Use pipeline -> process for loading GPT-2 text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Set your prompt\n",
    "prompt = 'Judge temporarily blocks effort to ban Harvard from enrolling foreign students'\n",
    "\n",
    "# Generate text\n",
    "result = generator(prompt, max_length=50, temperature=0.2)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c69a033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9am. I just brushed my teeth, and am now getting ready for the day! Thanks for all the support! I'm going to try and get to work after finishing my game.\n",
      "\n",
      "Advertisements\n",
      "What is 4 + 4 is the number of items that you can take out of your bag.\n",
      "\n",
      "I'm not saying that you should always use 4 + 4. You can use it in the same way as you would when you're trying to\n"
     ]
    }
   ],
   "source": [
    "# Experiment with different prompts\n",
    "prompt = '9am. I just brushed my teeth, and am now getting ready for the day!'\n",
    "result = generator(prompt, max_length=50, temperature=0.8)\n",
    "print(result[0]['generated_text'])\n",
    "\n",
    "prompt = 'What is 4 + 4?'\n",
    "result = generator(prompt, max_length=20, temperature=0.6)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d0d32",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Now that you have experimented with text generation, write a brief report on your observations.\n",
    "\n",
    "1. What patterns did you notice in the generated text?\n",
    "2. How did changing the temperature affect the creativity and coherence of the text?\n",
    "3. What types of prompts yielded the most coherent results?\n",
    "4. What are the limitations of GPT-2 based on your experimentation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
